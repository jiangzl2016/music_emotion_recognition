{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pathlib import Path\n",
    "import numpy as np, scipy, matplotlib.pyplot as plt, IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhonglingjiang/Desktop/Fall 2019/Big Data Analytics/music_emotion_recognition/libs\n"
     ]
    }
   ],
   "source": [
    "cd ../libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rp_extract.rp_extract import rp_extract\n",
    "from rp_extract.audiofile_read import *\n",
    "from rp_extract.rp_plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhonglingjiang/Desktop/Fall 2019/Big Data Analytics/music_emotion_recognition/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd ../notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = Path.cwd().parent / '1000songs' / 'clips_45seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now aggregate everything\n",
    "## Part I: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_val(d, k, v):\n",
    "    if k not in d:\n",
    "        d[k] = [v]\n",
    "    else:\n",
    "        d[k].append(v)\n",
    "    return d\n",
    "\n",
    "def temporal_centroid(envelope):\n",
    "    \"\"\"computes the temporal centroid of an onset envelope\"\"\"\n",
    "    D = np.abs(librosa.stft(envelope))\n",
    "    times = librosa.times_like(D)\n",
    "\n",
    "    onset_strength = librosa.onset.onset_strength(y=envelope, sr=sr)\n",
    "    \n",
    "    try:\n",
    "        temporal_centroid = sum(onset_strength * times) / sum(onset_strength)\n",
    "    except RuntimeWarning:\n",
    "        temporal_centroid = np.nan\n",
    "    \n",
    "    return temporal_centroid\n",
    "\n",
    "def log_attack_time(envelope, sr, thresh_percent):\n",
    "    D = np.abs(librosa.stft(envelope))\n",
    "    times = librosa.times_like(D)\n",
    "    onset_strength = librosa.onset.onset_strength(y=envelope, sr=sr)\n",
    "    \n",
    "    stop_attack_index = np.argmax(onset_strength)\n",
    "    stop_attack_value = envelope[stop_attack_index]\n",
    "    thresh = stop_attack_value * thresh_percent / 100\n",
    "    \n",
    "    try:\n",
    "        start_attack_index = [x > thresh for x in onset_strength].index(True)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    \n",
    "    if start_attack_index == stop_attack_index:\n",
    "        start_attack_index -= 1\n",
    "\n",
    "    log_attack_time =  np.log10(times[stop_attack_index] - times[start_attack_index])\n",
    "    \n",
    "    return log_attack_time\n",
    "\n",
    "def extract_features(signal, sr):\n",
    "    \"\"\"Given and a signal and its sampling rate, compute all the features\"\"\"\n",
    "    \n",
    "    # Temporal Features\n",
    "    onset_samples = np.unique(librosa.onset.onset_detect(signal, sr=sr, backtrack=True, units='samples'))\n",
    "    all_envelopes = np.split(signal, onset_samples)\n",
    "    \n",
    "    zero_crossings = np.array([sum(librosa.zero_crossings(x, pad=False)) for x in all_envelopes])\n",
    "    zero_features = np.array([np.mean(zero_crossings), np.std(zero_crossings)])\n",
    "    \n",
    "    temporal_centroids = np.array([temporal_centroid(x) for x in all_envelopes])\n",
    "    temporal_centroids = temporal_centroids[~np.isnan(temporal_centroids)]\n",
    "    temporal_cen_features = np.array([np.mean(temporal_centroids), np.std(temporal_centroids)])\n",
    "    \n",
    "    log_attacks = np.array([log_attack_time(x, sr, 50) for x in all_envelopes])\n",
    "    log_attacks = log_attacks[~np.isnan(log_attacks)]\n",
    "    log_attack_features = np.array([np.mean(log_attacks), np.std(log_attacks)])\n",
    "    \n",
    "    # Rhythmic Feautres (without dimension reduction for now)\n",
    "    rhythm = rp_extract(signal, sr, extract_rh=True, transform_db=True, transform_phon=True, transform_sone=True,          \n",
    "        fluctuation_strength_weighting=True, \n",
    "        skip_leadin_fadeout=1,             \n",
    "        step_width=1)\n",
    "    rhythm_hist = rhythm['rh']\n",
    "    rhythm_mean = np.array([np.mean(rhythm_hist)])\n",
    "    \n",
    "    all_features = np.concatenate([zero_features, temporal_cen_features, log_attack_features, rhythm_hist, rhythm_mean])\n",
    "    \n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [00:51<1:22:42,  5.01s/it]"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "audio_path = Path.cwd().parent / '1000songs' / 'clips_45seconds'\n",
    "all_mp3_paths = list(audio_path.glob('**/*.mp3'))\n",
    "song_ids = []\n",
    "audio_train = [] \n",
    "for path in tqdm(all_mp3_paths):\n",
    "    if len(audio_train) < 10: #we'll start off with only 10 training pieces to save time\n",
    "        signal, sr = librosa.load(str(path))\n",
    "        try:\n",
    "            song_features = extract_features(signal, sr)\n",
    "            audio_train.append(song_features)\n",
    "            song_ids.append(int((str(path).split('/')[-1].split('.')[0])))\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(path)\n",
    "            continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "audio_train = np.array(audio_train).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a test song\n",
    "test_song = '108.mp3'\n",
    "signal, sr = librosa.load(str(path))\n",
    "audio_test = extract_features(signal, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>[0,0]</th>\n",
       "      <th>[0,1]</th>\n",
       "      <th>[0,2]</th>\n",
       "      <th>[0,3]</th>\n",
       "      <th>[0,4]</th>\n",
       "      <th>[0,5]</th>\n",
       "      <th>[0,6]</th>\n",
       "      <th>[0,7]</th>\n",
       "      <th>[0,8]</th>\n",
       "      <th>...</th>\n",
       "      <th>[15,6]</th>\n",
       "      <th>[15,7]</th>\n",
       "      <th>[15,8]</th>\n",
       "      <th>[15,9]</th>\n",
       "      <th>[15,10]</th>\n",
       "      <th>[15,11]</th>\n",
       "      <th>[15,12]</th>\n",
       "      <th>[15,13]</th>\n",
       "      <th>[15,14]</th>\n",
       "      <th>[15,15]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.003236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003245</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.003769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.003434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.003988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id     [0,0]     [0,1]     [0,2]     [0,3]     [0,4]     [0,5]  \\\n",
       "0        2  0.003781  0.003843  0.003895  0.003934  0.003962  0.003978   \n",
       "1        3  0.003811  0.003870  0.003917  0.003952  0.003975  0.003986   \n",
       "2        4  0.003245  0.003330  0.003406  0.003473  0.003530  0.003577   \n",
       "3        5  0.003561  0.003652  0.003734  0.003806  0.003868  0.003918   \n",
       "4        7  0.003059  0.003153  0.003239  0.003318  0.003387  0.003448   \n",
       "\n",
       "      [0,6]     [0,7]     [0,8]  ...    [15,6]    [15,7]    [15,8]    [15,9]  \\\n",
       "0  0.003981  0.003972  0.003950  ...  0.003695  0.003687  0.003667  0.003636   \n",
       "1  0.003984  0.003970  0.003944  ...  0.003705  0.003692  0.003667  0.003632   \n",
       "2  0.003614  0.003639  0.003653  ...  0.003959  0.003987  0.004003  0.004006   \n",
       "3  0.003956  0.003983  0.003996  ...  0.003621  0.003645  0.003657  0.003659   \n",
       "4  0.003498  0.003539  0.003568  ...  0.004027  0.004073  0.004107  0.004129   \n",
       "\n",
       "    [15,10]   [15,11]   [15,12]   [15,13]   [15,14]   [15,15]  \n",
       "0  0.003594  0.003541  0.003479  0.003406  0.003325  0.003236  \n",
       "1  0.003585  0.003528  0.003461  0.003385  0.003300  0.003208  \n",
       "2  0.003996  0.003974  0.003940  0.003895  0.003837  0.003769  \n",
       "3  0.003649  0.003627  0.003595  0.003552  0.003498  0.003434  \n",
       "4  0.004137  0.004133  0.004115  0.004085  0.004043  0.003988  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_density = pd.read_csv('../Time_Average_Gamma_0_1.csv', header=0)\n",
    "kernel_density.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[752, 746, 791, 949, 785, 975, 961, 550, 236, 222]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just take a subsample - 4 songs ['752.mp3', '746.mp3', '791.mp3', '949.mp3' ]\n",
    "# For code debug purpose\n",
    "song_ids \n",
    "# selected_kernel_density = kernel_density.loc[kernel_density['song_id'].isin(selected_song_id), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_kernel_density.drop(['song_id'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Mapping Factor Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated β vector is: \n",
      "\n",
      "[ 0.25330639  0.59165405  0.30269512  0.10057767 -0.46341318  0.16934319  0.56199342  0.19025291 -0.97427703 -0.16782478]\n"
     ]
    }
   ],
   "source": [
    "# Non-negative sparse representation (SR+) seems require solution >0\n",
    "# Need to enforce additional condition\n",
    "\n",
    "lamda = 0.01\n",
    "def estimate(x, beta):\n",
    "    \"\"\"The function estimates linear outcome given an observation and a coeffcient vector.\"\"\"\n",
    "    yhat = np.dot(x, beta)\n",
    "    return yhat\n",
    "\n",
    "def RSS_L1(beta, X, y, lamda):\n",
    "    y_hat = np.dot(X, beta)\n",
    "    return np.sum((y - y_hat)**2) + lamda* np.sum(np.abs(beta))\n",
    "\n",
    "beta0 = np.random.normal(0, 1, audio_train.shape[1])\n",
    "res = minimize(fun=RSS_L1, x0=beta0, args=(audio_train, audio_test, lamda))\n",
    "beta_hat = res.x\n",
    "mapping_factors = beta_hat\n",
    "print('The estimated β vector is: \\n')\n",
    "print(mapping_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part IV: Emotion Space Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00159123, 0.00167126, 0.00174831, 0.00182168, 0.00189073, 0.00195482, 0.00201337, 0.00206584, 0.00211173, 0.00215062, ..., 0.00245644, 0.00250547, 0.00254659, 0.00257943, 0.00260368,\n",
       "       0.00261912, 0.00262563, 0.00262317, 0.0026118 , 0.00259165])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_emotion = np.zeros(16 * 16)\n",
    "for i, s_id in enumerate(song_ids):\n",
    "    if (kernel_density.loc[kernel_density['song_id'] == s_id, ].shape[0] == 0):\n",
    "        emotion_val = np.zeros(16 * 16)\n",
    "    else: \n",
    "        emotion_val = kernel_density.loc[kernel_density['song_id'] == s_id, ]. \\\n",
    "                        drop(['song_id'], axis=1).values[0]\n",
    "    pred_emotion += mapping_factors[i] * emotion_val\n",
    "pred_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01008467 0.01022267 0.01033025 0.01040642 0.01045046 0.01046197 0.01044083 0.01038725 0.01030172 0.01018504 ... 0.00970694 0.00965688 0.00957712 0.00946841 0.00933175 0.00916838 0.00897979\n",
      " 0.00876765 0.00853384 0.00828036]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Be aware of the order of songs when doing this step!\n",
    "# e = selected_kernel_density.drop(['song_id'], axis=1).values\n",
    "# pred_espace = np.dot(e.T, mapping_factors)\n",
    "# print(pred_espace)\n",
    "# len(pred_espace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicrecommendation",
   "language": "python",
   "name": "musicrecommendation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
