{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Relevant Packages / Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import numpy as np, scipy, matplotlib.pyplot as plt, IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeb/Documents/columbia_data_science/big_data/project/music_emotion_recognition/libs\n"
     ]
    }
   ],
   "source": [
    "cd ../libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rp_extract.rp_extract import rp_extract\n",
    "from rp_extract.audiofile_read import *\n",
    "from rp_extract.rp_plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeb/Documents/columbia_data_science/big_data/project/music_emotion_recognition/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd ../notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_centroid(envelope):\n",
    "    \"\"\"computes the temporal centroid of an onset envelope\"\"\"\n",
    "    D = np.abs(librosa.stft(envelope))\n",
    "    times = librosa.times_like(D)\n",
    "\n",
    "    onset_strength = librosa.onset.onset_strength(y=envelope, sr=sr)\n",
    "    \n",
    "    try:\n",
    "        temporal_centroid = sum(onset_strength * times) / sum(onset_strength)\n",
    "    except RuntimeWarning:\n",
    "        temporal_centroid = np.nan\n",
    "    \n",
    "    return temporal_centroid\n",
    "\n",
    "\n",
    "def log_attack_time(envelope, sr, thresh_percent):\n",
    "    D = np.abs(librosa.stft(envelope))\n",
    "    times = librosa.times_like(D)\n",
    "    onset_strength = librosa.onset.onset_strength(y=envelope, sr=sr)\n",
    "    \n",
    "    \n",
    "    stop_attack_index = np.argmax(onset_strength)\n",
    "    stop_attack_value = envelope[stop_attack_index]\n",
    "    thresh = stop_attack_value * thresh_percent / 100\n",
    "    \n",
    "    try:\n",
    "        start_attack_index = [x > thresh for x in onset_strength].index(True)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    \n",
    "    if start_attack_index == stop_attack_index:\n",
    "        start_attack_index -= 1\n",
    "\n",
    "    log_attack_time =  np.log10(times[stop_attack_index] - times[start_attack_index])\n",
    "    \n",
    "    return log_attack_time\n",
    "\n",
    "\n",
    "def extract_features(signal, sr):\n",
    "    \"\"\"Given and a signal and its sampling rate, compute all the features\"\"\"\n",
    "    \n",
    "    # Temporal Features\n",
    "    onset_samples = np.unique(librosa.onset.onset_detect(signal, sr=sr, backtrack=True, units='samples'))\n",
    "    all_envelopes = np.split(signal, onset_samples)\n",
    "    \n",
    "    zero_crossings = np.array([sum(librosa.zero_crossings(x, pad=False)) for x in all_envelopes])\n",
    "    zero_features = np.array([np.mean(zero_crossings), np.std(zero_crossings)])\n",
    "    \n",
    "    temporal_centroids = np.array([temporal_centroid(x) for x in all_envelopes])\n",
    "    temporal_centroids = temporal_centroids[~np.isnan(temporal_centroids)]\n",
    "    temporal_cen_features = np.array([np.mean(temporal_centroids), np.std(temporal_centroids)])\n",
    "\n",
    "    log_attacks = np.array([log_attack_time(x, sr, 50) for x in all_envelopes])\n",
    "    log_attacks = log_attacks[~np.isnan(log_attacks)]\n",
    "    log_attack_features = np.array([np.mean(log_attacks), np.std(log_attacks)])\n",
    "     \n",
    "    # Rhythmic Feautres (without dimension reduction for now)\n",
    "    rhythm = rp_extract(signal, sr, extract_rh=True, transform_db=True, transform_phon=True, transform_sone=True,          \n",
    "        fluctuation_strength_weighting=True, \n",
    "        skip_leadin_fadeout=1,             \n",
    "        step_width=1)\n",
    "    rhythm_hist = rhythm['rh']\n",
    "    rhythm_mean = np.array([np.mean(rhythm_hist)])\n",
    "    \n",
    "    all_features = np.concatenate([zero_features, temporal_cen_features, log_attack_features, rhythm_hist, rhythm_mean])\n",
    "\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct \"Dictionary of Audio Features of the Training Pieces\"\n",
    "\n",
    "To start we'll train on all but one song and use that song as our test (one hold out cv).\n",
    "\n",
    "Our \"dictionary\" will be PXQ where P = Number of features (67 in this example) and Q = Number of training samples (743 in this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all of our music data and create features\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "audio_path = Path.cwd().parent / 'data' / 'raw' / 'clips_45seconds'\n",
    "all_mp3_paths = list(audio_path.glob('**/*.mp3'))\n",
    "\n",
    "audio_train = [] \n",
    "for path in all_mp3_paths:\n",
    "    if len(audio_train) < 25: #we'll start off with only 25 training pieces to save time\n",
    "        signal, sr = librosa.load(str(path))\n",
    "        try:\n",
    "            song_features = extract_features(signal, sr)\n",
    "            audio_train.append(song_features)\n",
    "        except ValueError as e:\n",
    "            print(path)\n",
    "            continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "audio_train = np.array(audio_train).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Mapping Factors Learning\n",
    "\n",
    "We'll use the KNN algorithm with k=4. **I have to go back and scale the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take our training and testing, and reshape for the KNN algorithm\n",
    "\n",
    "y = audio_train[0, :]\n",
    "X = audio_train[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_factors(train, test):\n",
    "    \"\"\" Returns mapping factors vector based on 4-NN algorithm\n",
    "    train - a 2d np array of training data\n",
    "    test - a single test vector of data to\n",
    "    returns: a np array of the mapping factors of test\n",
    "    \"\"\"\n",
    "    nbrs = NearestNeighbors(n_neighbors=4, algorithm='ball_tree').fit(train)\n",
    "    _, indices = nbrs.kneighbors(test.reshape(-1, 1).T)\n",
    "    \n",
    "    map_fac = np.zeros(train.shape[0])\n",
    "    map_fac[indices] = 1\n",
    "    \n",
    "    return map_facnormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passes sum test: True\n",
      "Passes shape test: False\n"
     ]
    }
   ],
   "source": [
    "map_factors_test = map_factors(X, y)\n",
    "\n",
    "print(\"Passes sum test: {}\".format(sum(map_factors_test) == 4.0))\n",
    "print(\"Passes shape test: {}\".format(map_factors_test.shape == (24,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Space Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
